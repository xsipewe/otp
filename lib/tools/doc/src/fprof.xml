<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE erlref SYSTEM "erlref.dtd">

<erlref>
  <header>
    <copyright>
      <year>2001</year><year>2013</year>
      <holder>Ericsson AB. All Rights Reserved.</holder>
    </copyright>
    <legalnotice>
      Licensed under the Apache License, Version 2.0 (the "License");
      you may not use this file except in compliance with the License.
      You may obtain a copy of the License at
 
          http://www.apache.org/licenses/LICENSE-2.0

      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
    
    </legalnotice>

    <title>fprof</title>
    <prepared>Raimo Niskanen</prepared>
    <responsible></responsible>
    <docno></docno>
    <approved></approved>
    <checked></checked>
    <date>2001-08-13</date>
    <rev>PA1</rev>
    <file>fprof.xml</file>
  </header>
  <module>fprof</module>
  <modulesummary>A time profiling tool using trace to file for minimal
    runtime performance impact.</modulesummary>
  <description>
    <p>The <c>fprof</c> module is used to profile a program to determine
      how the execution time is used. Trace to file is used to minimize
      runtime performance impact.</p>
    <p>The module uses tracing to collect profiling data,
      hence there is no need for special compilation of modules to
      be profiled. When it starts tracing, Fprof performs the
      following:</p>
    <list type="bulleted">
      <item><p>Erases all previous tracing in the node.</p></item>
      <item><p>Sets the necessary trace flags on the profiling target
        processes.</p></item>
      <item><p>Sets local call trace on all functions in all loaded
        modules and in all modules to be loaded.</p></item>
    </list>
    <p>Fprof erases all tracing in the node when it stops tracing.</p>
    <p>The module presents both <em>own time</em> (how much time a
      function has used for its own execution) and <em>accumulated time</em>
      (including called functions). All presented times are
      collected using trace time stamps. Fprof tries to collect
      CPU time time stamps, if supported by the host machine OS.
      The times can therefore be wallclock times and OS scheduling
      randomly strikes all called functions in a presumably fair way.</p>
    <p>If, however, the profiling time is short, and the host machine
      OS does not support high-resolution CPU time measurements, a
      few OS schedulings can show up as ridiculously long execution
      times for functions doing practically nothing. An example of a
      function more or less only composing a tuple in about 100 times
      the normal execution time has been seen, and when the tracing
      was repeated, the execution time became normal.</p>
    <p>Profiling is done in three steps: tracing to file, profiling, and
      analyzing. For more information, see the User's Guide.</p>
    <marker id="start"></marker>
  </description>

  <funcs>
    <func>
      <name>start() -> {ok, Pid} | {error, {already_started, Pid}}</name>
      <fsummary>Starts the Fprof server.</fsummary>
      <type>
        <v>Pid = pid()</v>
      </type>
      <desc>
        <p>Starts the Fprof server.</p>
        <p>Notice that it seldom
          needs to be started explicitly, as it is automatically
          started by the functions that need a running server.</p>
        <marker id="stop"></marker>
      </desc>
    </func>

    <func>
      <name>stop() -> ok</name>
      <fsummary>Same as <c>stop(normal)</c>.</fsummary>
      <desc>
        <p>Same as <c>stop(normal)</c>.</p>
      </desc>
    </func>

    <func>
      <name>stop(Reason) -> ok</name>
      <fsummary>Stops the Fprof server.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Stops the Fprof server.</p>
        <p><c>Reason</c> becomes the exit reason for the server process.
          Any <c>Reason</c> other than <c>kill</c> sends a request to the
          server and waits for it to clean up, reply, and exit. If
          <c>Reason</c> is <c>kill</c>, the server is bluntly killed.</p>
        <p>If the Fprof server is not running, this
          function returns immediately with the same return value.</p>
        <note>
          <p>When the Fprof server is stopped, the
            collected raw profile data is lost.</p>
        </note>
        <marker id="apply"></marker>
      </desc>
    </func>

    <func>
      <name>apply(Func, Args) -> term()</name>
      <fsummary>Same as <c>apply(Func, Args, [])</c>.</fsummary>
      <type>
        <v>Func = function() | {Module, Function}</v>
        <v>Args = [term()]</v>
        <v>Module = atom()</v>
        <v>Function = atom()</v>
      </type>
      <desc>
        <p>Same as <c>apply(Func, Args, [])</c>.</p>
      </desc>
    </func>

    <func>
      <name>apply(Module, Function, Args) -> term()</name>
      <fsummary>Same as <c>apply({Module, Function}, Args, [])</c>.</fsummary>
      <type>
        <v>Args = [term()]</v>
        <v>Module = atom()</v>
        <v>Function = atom()</v>
      </type>
      <desc>
        <p>Same as <c>apply({Module, Function}, Args, [])</c>.</p>
      </desc>
    </func>

    <func>
      <name>apply(Func, Args, OptionList) -> term()</name>
      <fsummary>Calls <c>erlang:apply(Func, Args)</c> surrounded by
        <c>trace([start | OptionList])</c> and <c>trace(stop)</c>.</fsummary>
      <type>
        <v>Func = function() | {Module, Function}</v>
        <v>Args = [term()]</v>
        <v>OptionList = [Option]</v>
        <v>Module = atom()</v>
        <v>Function = atom()</v>
        <v>Option = continue | start | {procs, PidList} | TraceStartOption</v>
      </type>
      <desc>
        <p>Calls <c>erlang:apply(Func, Args)</c> surrounded by
          <c>trace([start, ...])</c> and <c>trace(stop)</c>.</p>
        <p>Some effort is made to keep the trace clean from unnecessary
          trace messages:</p>
        <list type="bulleted">
          <item><p>Tracing is started and stopped from a spawned
            process.</p></item>
          <item><p>The <c>erlang:apply/2</c> call is made in the
            current process, only surrounded by <c>receive</c> and
            <c>send</c> statements to the trace starting process.</p></item>
        </list>
        <p>The trace starting process exits when not needed anymore.</p>
        <p><c>TraceStartOption</c> is any option allowed for
          <c>trace/1</c>. The options
          <c>[start, {procs, [self() | PidList]} | OptList]</c>
          are specified to <c>trace/1</c>, where <c>OptList</c> is
          <c>OptionList</c> with <c>continue</c>, <c>start</c>, 
          and <c>{procs, _}</c> options removed.</p>
        <p>Option <c>continue</c> inhibits the call to
          <c>trace(stop)</c> and leaves it up to the caller to stop
          tracing at a suitable time.</p>
      </desc>
    </func>

    <func>
      <name>apply(Module, Function, Args, OptionList) -> term()</name>
      <fsummary>Same as <c>apply({Module, Function}, Args,
        OptionList)</c>.</fsummary>
      <type>
        <v>Module = atom()</v>
        <v>Function = atom()</v>
        <v>Args = [term()]</v>
      </type>
      <desc>
        <p>Same as <c>apply({Module, Function}, Args, OptionList)</c>.</p>
        <p><c>OptionList</c> is an option list allowed for
          <seealso marker="#apply-3"><c>apply/3</c></seealso>.</p>
        <marker id="trace"></marker>
      </desc>
    </func>

    <func>
      <name>trace(start, Filename) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([start, {file, Filename}])</c>.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([start, {file, Filename}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace(verbose, Filename) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([start, verbose, {file, Filename}])</c>.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([start, verbose, {file, Filename}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace(OptionName, OptionValue) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace(verbose) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([start, verbose])</c>.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([start, verbose])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace(OptionName) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([OptionName])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([OptionName])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace({OptionName, OptionValue}) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>trace([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>trace([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>trace([Option]) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Starts or stops tracing.</fsummary>
      <type>
        <v>Option = start | stop | {procs, PidSpec} | {procs, [PidSpec]} | verbose | {verbose, bool()} |  file | {file, Filename} | {tracer, Tracer}</v>
        <v>PidSpec = pid() | atom()</v>
        <v>Tracer = pid() | port()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Starts or stops tracing.</p>
        <p><c>PidSpec</c> and <c>Tracer</c> are used in calls to
          <c>erlang:trace(PidSpec, true, [{tracer, Tracer} | Flags])</c>,
          and <c>Filename</c> is used to call
          <c>dbg:trace_port(file, Filename)</c>, see
          <seealso marker="kernel:erlang"><c>kernel:erlang(3)</c></seealso>
          and
          <seealso marker="runtime_tools:dbg"><c>runtime_tools:dbg(3)</c></seealso>.</p>
        <p><em>Options:</em></p>
        <taglist>
          <tag><c>stop</c></tag>
          <item><p>Stops a running Fprof trace and clears all tracing
           from the node. Either option <c>stop</c> or <c>start</c> must be
           specified, but not both.</p></item>
          <tag><c>start</c></tag>
          <item><p>Clears all tracing from the node and starts a new
           Fprof trace. Either option <c>start</c> or
           <c>stop</c> must be specified, but not both.</p></item>
          <tag><c>verbose | {verbose, bool()}</c></tag>
          <item><p>Options <c>verbose</c> or <c>{verbose, true}</c>
           adds some trace flags that Fprof does not need, but
           that can be interesting for general debugging
           purposes. This option is only
           allowed with option <c>start</c>.</p></item>
          <tag><c>cpu_time | {cpu_time, bool()}</c></tag>
          <item><p>Options <c>cpu_time</c> or <c>{cpu_time, true></c>
           makes the time stamps in the trace be in CPU time instead
           of wallclock time, which is the default. This option is
           only allowed with option <c>start</c>.</p></item>
          <tag><c>{procs, PidSpec} | {procs, [PidSpec]}</c></tag>
          <item><p>Specifies which processes that are to traced. If
           this option is not specified, the calling process is
           traced. All processes spawned by the traced processes are
           also traced. This option is only allowed with option
           <c>start</c>.</p></item>
          <tag><c>file | {file, Filename}</c></tag>
          <item><p>Specifies the filename of the trace.
           If option <c>file</c> is specified, or none of these
           options are specified, file <c>"fprof.trace"</c> is used.
           This option is only allowed with option <c>start</c>,
           but not with option <c>{tracer, Tracer}</c>.</p></item>
          <tag><c>{tracer, Tracer}</c></tag>
          <item><p>Specifies that trace to process or port is to be done
           instead of trace to file. This option is only allowed with
           option <c>start</c>, but not with option
           <c>{file, Filename}</c>.</p></item>
        </taglist>
        <marker id="profile"></marker>
      </desc>
    </func>

    <func>
      <name>profile() -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>profile([])</c>.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>profile([])</c>.</p>
      </desc>
    </func>

    <func>
      <name>profile(OptionName, OptionValue) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>profile([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>profile([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>profile(OptionName) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>profile([OptionName])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>profile([OptionName])</c>.</p>
      </desc>
    </func>

    <func>
      <name>profile({OptionName, OptionValue}) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>profile([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>profile([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>profile([Option]) -> ok | {ok, Tracer} | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Compiles a trace into raw profile data held by the Fprof
        server.</fsummary>
      <type>
        <v>Option = file | {file, Filename} | dump | {dump, Dump} |  append | start | stop</v>
        <v>Dump = pid() | Dumpfile | []</v>
        <v>Tracer = pid()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Compiles a trace into raw profile data held by the Fprof server.</p>
        <p><c>Dumpfile</c> is used to call <c>file:open/2</c>,
          and <c>Filename</c> is used to call 
          <c>dbg:trace_port(file, Filename)</c>, see
          <seealso marker="kernel:file"><c>kernel:file(3)</c></seealso>
          and
          <seealso marker="runtime_tools:dbg"><c>runtime_tools:dbg(3)</c></seealso>.</p>
        <p><em>Options:</em></p>
        <taglist>
          <tag><c>file | {file, Filename}</c></tag>
          <item><p>Reads the file <c>Filename</c> and creates raw profile
           data that is stored in RAM by the Fprof server. If option
           <c>file</c> is specified, or none of these options are specified,
           file <c>"fprof.trace"</c> is read. The call returns when
           the whole trace is
           read with the return value <c>ok</c> if successful.
           This option is not allowed with options <c>start</c> or
           <c>stop</c>.</p></item>
          <tag><c>dump | {dump, Dump}</c></tag>
          <item><p>Specifies the destination for the trace text dump. If
           this option is not specified, no dump is generated. If option
           <c>dump</c> is specified, the destination is the group leader of
           the caller. Otherwise destination <c>Dump</c> is either the pid
           of an I/O device or a filename. If the filename is <c>[]</c>,
           <c>"fprof.dump"</c> is used instead. This option is not allowed
           with option <c>stop</c>.</p></item>
          <tag><c>append</c></tag>
          <item><p>Causes the trace text dump to be appended to the
           destination file. This option is only allowed with option  
           <c>{dump, Dumpfile}</c>.</p></item>
          <tag><c>start</c></tag>
          <item><p>Starts a tracer process that profiles trace data in
           runtime. The call returns immediately with return
           value <c>{ok, Tracer}</c> if successful.
           This option is not allowed with options <c>stop</c>,
           <c>file</c>, or  <c>{file, Filename}</c>.</p></item>
          <tag><c>stop</c></tag>
          <item><p>Stops the tracer process that profiles trace data in
           runtime. The return value is <c>ok</c> if successful.
           This option is not allowed with options <c>start</c>,
           <c>file</c>, or <c>{file, Filename}</c>.</p></item>
        </taglist>
        <marker id="analyse"></marker>
      </desc>
    </func>

    <func>
      <name>analyse() -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>analyse([])</c>.</fsummary>
      <type>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>analyse([])</c>.</p>
      </desc>

    </func>
    <func>
      <name>analyse(OptionName, OptionValue) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>analyse([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>analyse([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>analyse(OptionName) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>analyse([OptionName])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>analyse([OptionName])</c>.</p>
      </desc>
    </func>

    <func>
      <name>analyse({OptionName, OptionValue}) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Same as <c>analyse([{OptionName, OptionValue}])</c>.</fsummary>
      <type>
        <v>OptionName = atom()</v>
        <v>OptionValue = term()</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Same as <c>analyse([{OptionName, OptionValue}])</c>.</p>
      </desc>
    </func>

    <func>
      <name>analyse([Option]) -> ok | {error, Reason} |  {'EXIT', ServerPid, Reason}</name>
      <fsummary>Analyzes raw profile data in the Fprof server.</fsummary>
      <type>
        <v>Option = dest | {dest, Dest} | append | {cols, Cols} |  callers | {callers, bool()} | no_callers | {sort, SortSpec} | totals | {totals, bool()} |  details | {details, bool()} | no_details</v>
        <v>Dest = pid() | Destfile</v>
        <v>Cols = integer() >= 80</v>
        <v>SortSpec = acc | own</v>
        <v>Reason = term()</v>
      </type>
      <desc>
        <p>Analyzes raw profile data in the Fprof server.
          If called while there is no raw
          profile data available, <c>{error, no_profile}</c> is returned.</p>
        <p><c>Destfile</c> is used to call <c>file:open/2</c>, see
          <seealso marker="kernel:file"><c>kernel:file(3)</c></seealso>.</p>
        <p><em>Options:</em></p>
        <taglist>
          <tag><c>dest | {dest, Dest}</c></tag>
          <item><p>Specifies the destination for the analysis. If
           this option is not specified, or it is <c>dest</c>,
           the destination is the group leader of the caller. 
           Otherwise the destination <c>Dest</c> is either
           the <c>pid()</c> of an I/O device or a filename.
           If the filename is <c>[]</c>,
           <c>"fprof.analysis"</c> is used instead.</p></item>
          <tag><c>append</c></tag>
          <item><p>Causes the analysis to be appended to the
           destination file. This option is only allowed with option
           <c>{dest, Destfile}</c>.</p></item>
          <tag><c>{cols, Cols}</c></tag>
          <item><p>Specifies the number of columns in the analysis text.
           If this option is not specified, the number of columns is set
           to 80.</p></item>
          <tag><c>callers | {callers, true}</c></tag>
          <item><p>Prints callers and called information in the
           analysis. This is the default.</p></item>
          <tag><c>{callers, false} | no_callers</c></tag>
          <item><p>Suppresses the printing of callers and called
           information in the analysis.</p></item>
          <tag><c>{sort, SortSpec}</c></tag>
          <item><p>Specifies if the analysis is to be sorted according
           to column <c>ACC</c>, which is the default, or column <c>OWN</c>.
           See section
           <seealso marker="#analysis">Analysis Format</seealso>.</p></item>
          <tag><c>totals | {totals, true}</c></tag>
          <item><p>Includes a section, containing call statistics
           for all calls regardless of process, in the analysis.</p></item>
          <tag><c>{totals, false}</c></tag>
          <item><p>Supresses the totals section in the analysis,
           which is the default.</p></item>
          <tag><c>details | {details, true}</c></tag>
          <item><p>Prints call statistics for each process in the
           analysis. This is the default.</p></item>
          <tag><c>{details, false} | no_details</c></tag>
          <item><p>Suppresses the call statistics for each process from
           the analysis.</p></item>
        </taglist>
      </desc>
    </func>
  </funcs>

  <section>
    <marker id="analysis"></marker>
    <title>Analysis Format</title>
    <p>This section describes the output format of command
      <seealso marker="#analyse"><c>analyse/0</c></seealso>.</p>
    <p>The format is parsable with the standard Erlang parsing tools
      <c>erl_scan</c> and <c>erl_parse</c>, <c>file:consult/1</c>, or
      <c>io:read/2</c>. The parse format is not explained here, as it
      is easy for the interested to try it out. Notice that some
      flags to <c>analyse/1</c> affect the format.</p>
    <p>The following example was run on OTP R8 on Solaris 8, all OTP
      internals in this example are very version-dependent.</p>
    <p>As an example, the following function is used.
      It is a slightly modified benchmark function from the
      <seealso marker="kernel:file"><c>kernel:file(3)</c></seealso>
      manual page:</p>

    <code type="none"><![CDATA[
-module(foo).
-export([create_file_slow/2]).

create_file_slow(Name, N) when integer(N), N >= 0 ->
    {ok, FD} = 
        file:open(Name, [raw, write, delayed_write, binary]),
    if N > 256 ->
            ok = file:write(FD, 
                            lists:map(fun (X) -> <<X:32/unsigned>> end,
                            lists:seq(0, 255))),
            ok = create_file_slow(FD, 256, N);
       true ->
            ok = create_file_slow(FD, 0, N)
    end,
    ok = file:close(FD).

create_file_slow(FD, M, M) ->
    ok;
create_file_slow(FD, M, N) ->
    ok = file:write(FD, <<M:32/unsigned>>),
    create_file_slow(FD, M+1, N).]]></code>

    <p>Examine the printout after running:</p>

    <pre>
1> <input>fprof:apply(foo, create_file_slow, [junk, 1024]).</input>
2> <input>fprof:profile().</input>
3> <input>fprof:analyse().</input></pre>

    <p>The printout starts with:</p>

    <pre>
%% Analysis results:
{  analysis_options,
 [{callers, true},
  {sort, acc},
  {totals, false},
  {details, true}]}.

%                                       CNT       ACC       OWN        
[{ totals,                             9627, 1691.119, 1659.074}].  %%%</pre>
 
    <p>The columns are as follows:</p>
    <list type="bulleted">
      <item><p><c>CNT</c> shows the total number of function calls
        found in the trace.</p></item>
      <item><p><c>ACC</c> shows the total time of the trace from the first
        time stamp to the last.</p></item>
      <item><p><c>OWN</c> shows the sum of the execution time in functions
        found in the trace, excluding called functions. In this case,
        it is very close to the <c>ACC</c> time, as the emulator
        practically did nothing else than to execute the test
        program.</p></item>
    </list>
    <p>All time values in the printout are in milliseconds.</p>
    <p>The printout continues:</p>

    <pre>
%                                       CNT       ACC       OWN        
[{ "&lt;0.28.0>",                         9627,undefined, 1659.074}].   %%</pre>

    <p>This is the printout header of one process. The printout
      contains only this one process, as <c>apply/3</c>
      traces only the current process. Therefore columns <c>CNT</c> and
      <c>OWN</c> perfectly match the totals above. Column <c>ACC</c> is
      undefined, as summing the <c>ACC</c> times of all calls in the process
      makes no sense; you would get something like the <c>ACC</c> value from
      <c>totals</c> above multiplied by the average depth of the call stack,
      or something similar.</p>
    <p>All paragraphs up to the next process header only concerns
      function calls within this process.</p>
    <p>Here is something more interesting:</p>

    <pre>
{[{undefined,                             0, 1691.076,    0.030}],     
 { {fprof,apply_start_stop,4},            0, 1691.076,    0.030},     %
 [{{foo,create_file_slow,2},              1, 1691.046,    0.103},      
  {suspend,                               1,    0.000,    0.000}]}.    

{[{{fprof,apply_start_stop,4},            1, 1691.046,    0.103}],     
 { {foo,create_file_slow,2},              1, 1691.046,    0.103},     %
 [{{file,close,1},                        1, 1398.873,    0.019},      
  {{foo,create_file_slow,3},              1,  249.678,    0.029},      
  {{file,open,2},                         1,   20.778,    0.055},      
  {{lists,map,2},                         1,   16.590,    0.043},      
  {{lists,seq,2},                         1,    4.708,    0.017},      
  {{file,write,2},                        1,    0.316,    0.021}]}.</pre>

    <p>The printout consists of one paragraph per called function. Each
      function <em>marked</em> with <c>%</c> is the one that the paragraph
      concerns, for example, <c>foo:create_file_slow/2</c>. Above the marked
      function are the <em>calling</em> functions (that called the
      marked function) and below are those <em>called</em> by the
      marked function.</p>
    <p>The paragraphs are by default sorted in decreasing order of
      the <c>ACC</c> column for the marked function. The calling list and
      the called list within one paragraph are also by default sorted in
      decreasing order of their <c>ACC</c> column.</p>
    <p>The columns are as follows:</p>
    <list type="bulleted">
      <item><p><c>CNT</c> shows the number of times the function is
        called.</p></item>
      <item><p><c>ACC</c> shows the time spent in the function including
        called functions.</p></item>
      <item><p><c>OWN</c> shows the time spent in the function
        excluding called functions.</p></item>
    </list>
    <p>The rows for the <em>calling</em> functions contain statistics
      for the <em>marked</em> function with the constraint that only
      the occasions when a call was made from the <em>row's</em>
      function to the <em>marked</em> function are accounted for.</p>
    <p>The row for the <em>marked</em> function simply contains the
      sum of all <em>calling</em> rows.</p>
    <p>The rows for the <em>called</em> functions contain statistics
      for the <em>row's</em> function with the constraint that only the
      occasions when a call was made from the <em>marked</em> to the
      <em>row's</em> function are accounted for.</p>
    <p>So, function <c>foo:create_file_slow/2</c> used very little
      time for its own execution. It spent most of its time in
      <c>file:close/1</c>. Function <c>foo:create_file_slow/3</c>,
      which writes 3/4 of the file contents, is the second biggest time
      thief.</p>
    <p>The call to <c>file:write/2</c>, which writes
      1/4 of the file contents, takes very little time in itself. What
      takes time is to build the data (<c>lists:seq/2</c> and
      <c>lists:map/2</c>).</p>
    <p>Function 'undefined', which called
      <c>apply_start_stop/4</c>, is an unknown function, as that
      call was not recorded in the trace. It was only recorded
      that the execution returned from
      <c>apply_start_stop/4</c> to some other function above in
      the call stack, or that the process exited from there.</p>
    <p>Further down, the printout contains the following:</p>

    <pre>
{[{{foo,create_file_slow,2},              1,  249.678,    0.029},      
  {{foo,create_file_slow,3},            768,    0.000,   23.294}],     
 { {foo,create_file_slow,3},            769,  249.678,   23.323},     %
 [{{file,write,2},                      768,  220.314,   14.539},      
  {suspend,                              57,    6.041,    0.000},      
  {{foo,create_file_slow,3},            768,    0.000,   23.294}]}.</pre>

    <p>If you compare with the code, you find that
      <c>foo:create_file_slow/3</c> was called only from
      <c>foo:create_file_slow/2</c> and itself, and called only
      <c>file:write/2</c>. Notice the number of calls to
      <c>file:write/2</c>.</p>
    <p>You also find that <c>suspend</c> was
      called a few times. This is a pseudo function indicating
      that the process was suspended while executing in
      <c>foo:create_file_slow/3</c>. Since there is no
      <c>receive</c> or <c>erlang:yield/0</c> in the code, it must be
      Erlang scheduling suspensions, or the trace file driver
      compensating for large file write operations (these are regarded
      as a schedule out followed by a schedule in to the same process).</p>
    <p>Examine the <c>suspend</c> entry:</p>

    <pre>
{[{{file,write,2},                       53,    6.281,    0.000},      
  {{foo,create_file_slow,3},             57,    6.041,    0.000},      
  {{prim_file,drv_command,4},            50,    4.582,    0.000},      
  {{prim_file,drv_get_response,1},       34,    2.986,    0.000},      
  {{lists,map,2},                        10,    2.104,    0.000},      
  {{prim_file,write,2},                  17,    1.852,    0.000},      
  {{erlang,port_command,2},              15,    1.713,    0.000},      
  {{prim_file,drv_command,2},            22,    1.482,    0.000},      
  {{prim_file,translate_response,2},     11,    1.441,    0.000},      
  {{prim_file,'-drv_command/2-fun-0-',1},  15,    1.340,    0.000},      
  {{lists,seq,4},                         3,    0.880,    0.000},      
  {{foo,'-create_file_slow/2-fun-0-',1},   5,    0.523,    0.000},      
  {{erlang,bump_reductions,1},            4,    0.503,    0.000},      
  {{prim_file,open_int_setopts,3},        1,    0.165,    0.000},      
  {{prim_file,i32,4},                     1,    0.109,    0.000},      
  {{fprof,apply_start_stop,4},            1,    0.000,    0.000}],     
 { suspend,                             299,   32.002,    0.000},     %
 [ ]}.</pre>

    <p>There are no particularly long suspend times, so no function seems
      to have waited in a <c>receive</c> statement. Although
      <c>prim_file:drv_command/4</c> contains a <c>receive</c> statemen
      in this test program, the message lies in the process receive
      buffer when the <c>receive</c> statement is entered. Also,
      the total suspend time for the test run is small.</p>
    <p>The <c>suspend</c> pseudo function has an <c>OWN</c> time of
      zero. This is to prevent the process total <c>OWN</c> time from
      including time in suspension. Whether suspend time is <c>ACC</c>
      or <c>OWN</c> time is more of a philosophic question.</p>
    <p>Another interesting pseudo function is <c>garbage_collect</c>:</p>

    <pre>
{[{{prim_file,drv_command,4},            25,    0.873,    0.873},      
  {{prim_file,write,2},                  16,    0.692,    0.692},      
  {{lists,map,2},                         2,    0.195,    0.195}],     
 { garbage_collect,                      43,    1.760,    1.760},     %
 [ ]}.</pre>

    <p>No function distinguishes itself considerably, which is normal.</p>
    <p>The <c>garbage_collect</c> pseudo function has got an <c>OWN</c>
      time of zero like <c>suspend</c>, instead it is equal to the <c>ACC</c>
      time.</p>
    <p>Garbage collect often occurs while a process is suspended, but
      Fprof hides this fact by pretending that the suspended
      function was first unsuspended and then garbage
      collected. Otherwise the printout would show
      <c>garbage_collect</c> being called from <c>suspend</c>, but not
      which function that could have caused the garbage collection.</p>
    <p>Back to the test code:</p>

    <pre>
{[{{foo,create_file_slow,3},            768,  220.314,   14.539},      
  {{foo,create_file_slow,2},              1,    0.316,    0.021}],     
 { {file,write,2},                      769,  220.630,   14.560},     %
 [{{prim_file,write,2},                 769,  199.789,   22.573},      
  {suspend,                              53,    6.281,    0.000}]}.    </pre>

    <p>Not unexpectedly, you see that <c>file:write/2</c> was called
      from <c>foo:create_file_slow/3</c> and
      <c>foo:create_file_slow/2</c>. The number of calls in each case
      and the used time also confirms the previous results.</p>
    <p>You see that <c>file:write/2</c> only calls
      <c>prim_file:write/2</c>.</p>
    <p>If you dig down into the internals of the <c>Kernel</c> application,
      you find the call to the linked-in driver that does the file operations
      to the host operating system:</p>

    <pre>
{[{{prim_file,drv_command,4},           772, 1458.356, 1456.643}],     
 { {erlang,port_command,2},             772, 1458.356, 1456.643},     %
 [{suspend,                              15,    1.713,    0.000}]}.    </pre>

    <p>This is 86% of the total runtime. Operation <c>close</c> is the
      absolutely biggest contributor, as was found earlier. There is a
      comparison ratio a little bit up in the call stack:</p>

     <pre>
{[{{prim_file,close,1},                   1, 1398.748,    0.024},      
  {{prim_file,write,2},                 769,  174.672,   12.810},      
  {{prim_file,open_int,4},                1,   19.755,    0.017},      
  {{prim_file,open_int_setopts,3},        1,    0.147,    0.016}],     
 { {prim_file,drv_command,2},           772, 1593.322,   12.867},     %
 [{{prim_file,drv_command,4},           772, 1578.973,   27.265},      
  {suspend,                              22,    1.482,    0.000}]}.    </pre>

    <p>The time for file operations in the linked-in driver
      distributes itself as 1% for <c>open</c>, 11% for <c>write</c>,
      and 87 % for <c>close</c>. All data is probably buffered in the
      operating system until <c>close</c>.</p>
    <p>Notice that the <c>ACC</c> times for <c>prim_file:drv_command/2</c>
      and <c>prim_file:drv_command/4</c> are not equal, although it is
      easy to believe that
      <c>prim_file:drv_command/2</c> is only a passthrough function.</p>
    <p>The missing time can be found
      for <c>prim_file:drv_command/4</c>, where it is evident that not
      only <c>prim_file:drv_command/2</c> is called but also a fun:</p>

    <pre>
{[{{prim_file,drv_command,2},           772, 1578.973,   27.265}],     
 { {prim_file,drv_command,4},           772, 1578.973,   27.265},     %
 [{{erlang,port_command,2},             772, 1458.356, 1456.643},      
  {{prim_file,'-drv_command/2-fun-0-',1}, 772,   87.897,   12.736},      
  {suspend,                              50,    4.582,    0.000},      
  {garbage_collect,                      25,    0.873,    0.873}]}.    </pre>

    <p>Some more missing time can be explained by the fact that
      <c>prim_file:open_int/4</c> calls
      <c>prim_file:drv_command/2</c> directly but also through
      <c>prim_file:open_int_setopts/3</c>, which complicates the
      picture:</p>

     <pre>
{[{{prim_file,open,2},                    1,   20.309,    0.029},      
  {{prim_file,open_int,4},                1,    0.000,    0.057}],     
 { {prim_file,open_int,4},                2,   20.309,    0.086},     %
 [{{prim_file,drv_command,2},             1,   19.755,    0.017},      
  {{prim_file,open_int_setopts,3},        1,    0.360,    0.032},      
  {{prim_file,drv_open,2},                1,    0.071,    0.030},      
  {{erlang,list_to_binary,1},             1,    0.020,    0.020},      
  {{prim_file,i32,1},                     1,    0.017,    0.017},      
  {{prim_file,open_int,4},                1,    0.000,    0.057}]}.    
.
.
.
{[{{prim_file,open_int,4},                1,    0.360,    0.032},      
  {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}],     
 { {prim_file,open_int_setopts,3},        2,    0.360,    0.048},     %
 [{suspend,                               1,    0.165,    0.000},      
  {{prim_file,drv_command,2},             1,    0.147,    0.016},      
  {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}]}.</pre>
  </section>

  <section>
    <title>Notes</title>
    <p>The supervision of execution times is in itself a
      CPU intensive activity. A message is written on the trace file
      for every function call that is made by the profiled code.</p>
    <p>The <c>ACC</c> time calculation is sometimes difficult to make
      correct, as it is difficult to define. This happens
      especially when a function occurs in many instances in the
      call stack, for example, by calling itself perhaps through other
      functions and even non-tail recursively.</p>
    <p>To produce sensible results, Fprof tries not to charge
      any function more than once for <c>ACC</c> time. The instance highest
      up (with longest duration) in the call stack is chosen.</p>
    <p>Sometimes a function can unexpectedly waste much (some 10 ms or more
      depending on the host machine OS) of <c>OWN</c> (and <c>ACC</c>) time,
      even functions that do practically nothing. The reason can
      be that the OS has chosen to schedule out the
      Erlang runtime system process for a while. If the OS does
      not support high-resolution CPU time measurements,
      Fprof uses wallclock time for its calculations, and
      it then seems that functions randomly burn virtual machine time.</p>
  </section>

  <section>
    <title>See Also</title>
    <p><seealso marker="eprof"><c>eprof(3)</c></seealso>,
    <seealso marker="kernel:erlang"><c>kernel:erlang(3)</c></seealso>,
    <seealso marker="kernel:file"><c>kernel:file(3)</c></seealso>,
    <seealso marker="runtime_tools:dbg"><c>runtime_tools:dbg(3)</c></seealso>,
    <seealso marker="stdlib:io"><c>stdlib:io(3)</c></seealso></p>
  </section>
</erlref>

